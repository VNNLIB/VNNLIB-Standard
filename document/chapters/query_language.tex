\chapter{\vnnlib{} Query Language}\label{sec:specification_language}

At the heart of the \vnnlib{} standard is the \vnnlib{} query language. Heavily influenced by SMT-LIB, this language is designed as a standardised computer-readable format for defining a wide range of satisfiability queries over neural networks. This chapter describes the syntax, scoping, typing and semantics of the query language.

\section{Syntax}
\label{sec:syntax}

The syntax of \vnnlib{} is formally defined as Labelled Backus-Naur Form~\cite{8} (LBNF) grammar which can be found in Appendix~\ref{app:lbnf_grammar}. Instead of going over the production rules in gory detail, we will now highlight key syntactic constructs of the language via examples illustrating their usage.
\vnnlib{} queries are split into two parts: network declarations and assertions.

\subsection{Network declarations}
\label{sec:network-declarations}
A network declaration is introduced by the keyword \texttt{declare-network}, followed by a user-defined variable name for the network, 
and then its associated input, hidden, and output variable declarations. Figure~\ref{fig:simple_net} shows a simple network declaration along with its ONNX
model representation.

\begin{figure}[h!]
    \begin{minipage}[c]{0.6\textwidth}
        \begin{lstlisting}[
            style=lbnf,
            label={lst:network_definition}
        ]
(declare-network simple_net
    (declare-input X Real [1,10])
    (declare-output Y Real [1,2])
)\end{lstlisting}
    \end{minipage}%
    \begin{minipage}[c]{0.45\textwidth}
        \centering
        \includegraphics[height=6cm]{imgs/simple_net.onnx.png}
    \end{minipage}
    \caption{A simple \vnnlib{} network declaration.}
    \label{fig:simple_net}
\end{figure}
\mnote{The diagrams look really good, but in all of them please can you:

1) make the networks match as closely as possible in height to the query next to them. For example in 3.1, can you remove one of the two hidden nodes? 

2) avoid naming the I/O nodes in the picture the same as the names used in the query. We don't want to give the impression that they need to be the same!

3) Render the input and output dimensions of the input and output nodes on the image. Those are really important as they do have to match. You can definitely see them on Netron.

4) Can you update all the queries to the syntax proposed in Issue \#63? }

All variables are declared inside of network declarations.  The network name (e.g., \texttt{simple\_net} below) is used by the verifier to 
associate the declared network with a specific ONNX file provided via the command line (as described in Chapter~\ref{sec:solver_interface}) while the variable names 
(e.g., \texttt{X}, \texttt{Y}) are used to reference nodes inside of the ONNX graph. 

All variable names follow the same syntax conventions. Variable names in \vnnlib{} are case-sensitive, must start with a letter, and may only contain letters, digits and underscores. All variable names must
be unique across the scope of the \vnnlib{} query. 

% The \texttt{@} character is a reserved character which is used to denote multiple applications of the same network, for the purpose of defining  hyperproperties such as monotonicity. For example \texttt{(declare-network acasXu@1 ...)} and \texttt{(declare-network acasXu@2 ...)} define two networks that are both instances of the same ONNX model,  denoted as \texttt{acasXu} in the command line interface of the verifier (See Chapter~\ref{sec:solver_interface} for more details).

\subsubsection*{Input and Output Variable Declarations}
\label{sec:input-output-declarations}
An input variable is declared using the \texttt{declare-input} keyword, followed by a variable name, its element type (e.g., \texttt{Real}, \texttt{int8}), 
and a list of integers representing the shape of the tensor. Similarly, an output variable uses the \texttt{declare-output} keyword. Multiple 
input and output variables can be declared within a single network declaration. There are two ways to map these declared variables to the nodes in the ONNX model:
\begin{enumerate}
    \item \textbf{Ordered Mapping (Default):} The variables are mapped to the ONNX graph's inputs/outputs based on their order of declaration. This is demonstrated in Example~\ref{lst:ordered_mapping}
    \item \textbf{Explicit Name Mapping:} Alternatively, variables can be explicitly mapped using its identifier within the ONNX graph. If this method is used, all input and output 
        variables within that network declaration must be given an explicit ONNX node name. This is demonstrated in Example~\ref{lst:named_mapping}.
\end{enumerate}

\begin{figure}[h!]
    \centering
    \begin{lstlisting}[
        caption={A network with multiple inputs/outputs, mapped by declaration order.},
        style=lbnf,
        label={lst:ordered_mapping}
    ]
(declare-network multi_io_net
    (declare-input image Real 1 3 224 224)
    (declare-input metadata Real 1 10)
    (declare-output logits Real 1 1000)
    (declare-output bbox Real 1 4)
)
    \end{lstlisting}
    \begin{lstlisting}[
        caption={The same network, but with explicit ONNX node name mapping.},
        style=lbnf,
        label={lst:named_mapping}
    ]
(declare-network multi_io_net
    (declare-input image Real 1 3 224 224 onnx-node:"image")
    (declare-input metadata Real 1 10 onnx-node:"metadata")
    (declare-output logits Real 1 1000 onnx-node:"logits")
    (declare-output bbox Real 1 4 onnx-node:"bbox")
)
    \end{lstlisting}
    \vspace{0.5cm}
    \includegraphics[height=10cm]{imgs/multi_io_net.onnx.png}
    \caption{A \vnnlib{} network declaration with multiple inputs and outputs. The first example uses ordered mapping, while the second uses explicit ONNX node names.}
    \label{fig:multi_io_net}
\end{figure}


\paragraph{Hidden Node Declarations}
\label{sec:hidden-node-declarations}
In some verification applications is necessary to reason about the result of intermediate computation results at hidden nodes within the network, such as encoding features, attention mechanisms, or other internal states.
This can be achieved by declaring hidden nodes is declared using the \texttt{declare-hidden} keyword. This declaration includes a variable name for use within the \vnnlib{} specification, 
its element type, its tensor shape, and crucially, a string identifier that specifies the corresponding node name in the ONNX graph.  Multiple
hidden nodes can be trivially declared within a single network declaration. Figure~\ref{fig:hidden_node} shows an example of a \vnnlib{} network declaration with a hidden node.

\begin{figure}[h!]
    \begin{minipage}[c]{0.55\textwidth}
        \begin{lstlisting}[
            style=lbnf,
            label={lst:hidden_node}
        ]
(declare-network encoder
    (declare-input X Real 1 28 28)
    (declare-hidden feature_embedding Real 1 128 onnx-node:"encoder_layer4/output")
    (declare-output Y Real 1 10)
)
        \end{lstlisting}
    \end{minipage}%
    \begin{minipage}[c]{0.45\textwidth}
        \centering
        \includegraphics[height=8cm]{imgs/encoder_net.onnx.png}
    \end{minipage}
    \caption{A \vnnlib{} network declaration with a hidden node. The hidden node \texttt{feature\_embedding} corresponds to the ONNX node \texttt{encoder\_layer4/output}.}
    \label{fig:hidden_node}
\end{figure}

\subsubsection*{Multiple networks}
\label{sec:multi-network-declarations}
\vnnlib{} supports defining multiple networks in a single file by including multiple `(declare-network ...)` expressions. This is essential for properties that compare networks, 
such as checking for equivalence between two models or verifying properties of a composite system, like an observer-controller architecture. Figure~\ref{fig:multi_network} 
shows an example of a \vnnlib{} file that declares two networks, \texttt{teacher\_net} and \texttt{student\_net}.

\begin{figure}[h!]
    \begin{minipage}[c]{0.57\textwidth}
        \begin{lstlisting}[style=lbnf]
(declare-network teacher
    (declare-input  x Real [1,32])
    (declare-output y Real [1,2])
)

(declare-network student
    (declare-input  a Real [1,32])
    (declare-output b Real [1,2])
)\end{lstlisting}
    \end{minipage}
    \begin{minipage}[c]{0.43\textwidth}
        \centering
        \includegraphics[height=8cm]{imgs/teacher_net.onnx.png}
        \vspace{0.5cm} 
        \includegraphics[height=8cm]{imgs/student_net.onnx.png}
    \end{minipage}
    \caption{Two networks declared in \vnnlib{}: \texttt{teacher\_net} and \texttt{student\_net}.}
    \label{fig:multi_network}
\end{figure}

\subsection{Assertion Example}

\subsubsection*{Assertion declarations}
\label{sec:assertion-declarations}
\vnnlib{} supports quantifier-free logical formulas as \textit{assertions}. Assertions are defined using parenthesized \texttt{(assert\ldots)} expressions, and following an SMT-LIB-like syntax with the 
operator preceding its operands. An assertion is a logical formula that may include logical connectives, relational comparisons, and arithmetic expressions over declared tensors and constants.

\subsubsection*{Variables and Indexing}
\label{sec:variables-and-indexing}
Assertions may only refer to individual elements of declared tensors. To refer to a specific scalar element within a tensor, an indexing notation is used. Let $X \in I$ be an $n$-dimensional tensor 
in some generic input domain $I = I^{d_1 \times \cdots \times d_n}$. The ``matrix notation'' represents a specific element $x_{i_1, i_2, \dots, i_n}$ of the tensor $X$ as \texttt{X[$i_1$,$i_2$,\dots,$i_n$]}, 
where $i_1, \dots, i_n$ are zero-based indices ranging from $0$ to $d_1{-}1$, $0$ to $d_2{-}1$, \dots, $d_n{-}1$, respectively. To better clarify, if we consider the 1-D tensor $X \in I^n$, the 2-D tensor 
$Y \in I^{n \times m}$, and the 3-D tensor $Z \in I^{n \times m \times p}$, we will have the following representations:
\begin{itemize}
    \item \texttt{X[0]}, \texttt{X[1]}, \dots, \texttt{X[$i$]}, \dots, \texttt{X[$n$]};
    \item \texttt{Y[0,0]}, \texttt{Y[0,1]}, \dots, \texttt{Y[$i$,$j$]}, \dots, \texttt{Y[$n$,$m$]};
    \item \texttt{Z[0,0,0]}, \texttt{Z[0,0,1]}, \dots, \texttt{Z[$i$,$j$,$k$]}, \dots, \texttt{Z[$n$,$m$,$p$]};
\end{itemize}
In such a representation, \texttt{Z[$i$-$j$-$k$]} corresponds to the element $z_{i,j,k}$ of the tensor $Z$. 

\subsubsection*{Arithmetic expressions}
Arithmetic expressions are formed using prefix notation with the following supported operators:
\begin{itemize}
    \item \texttt{(+ a b ...)}: Addition of two or more terms. 
    \item \texttt{(- a b ...)}: Subtraction of two or more terms. Alternatively, \texttt{(- a)} for negation.
    \item \texttt{(* a b ...)}: Multiplication of two or more terms. 
\end{itemize}
Operands (\texttt{a}, \texttt{b},...) can be constants, indexed tensors, or other nested arithmetic expressions.

\subsubsection*{Boolean expressions}
Boolean expressions are defined as expressions that produce a Boolean (\texttt{true} or \texttt{false}) value. They are formed using comparison operators and logical connectives:
\begin{itemize}
    \item \textbf{Comparison Operators:} \texttt{<=}, \texttt{>=}, \texttt{<}, \texttt{>}, \texttt{=}, \texttt{!=}
    \begin{itemize}
        \item The operands may be constants, indexed tensors, or arithmetic expressions. Each operator has two operands.
        \item For example \texttt{(<= a b)} returns true if $a$ is less than or equal to $b$.
    \end{itemize}
    \item \textbf{Logical Connectives:} \texttt{and}, \texttt{or}
    \begin{itemize}
        \item The operands must be Boolean expressions. Each operator can take two or more operands.
        \item For example \texttt{(and a b ...)} returns true if all operands are true.
    \end{itemize}
\end{itemize}

\begin{lstlisting}[
    caption={An assertion stating that if the input $A_0$ is between 0 and 1, the output $B_0$ must be greater than $B_1$ and their sum must be non-negative.},
    style=lbnf,
    label={lst:assertion-example}
]
(assert
    (and
        (and (>= A_0 0.0) (<= A_0 1.0))
        (and (> B_0 B_1) (>= (+ B_0 B_1) 0.0))
    )
)
\end{lstlisting}

\subsection{Comments and whitespace}

Comments in \vnnlib{} are denoted by a semicolon (\texttt{;}) and extend to the end of the line. They are used for annotation, explaining logic, or providing additional context. Whitespace in \vnnlib{} is used to separate tokens and improve readability. It can include spaces, tabs, and newlines. Whitespace is ignored by the parser, except where it is necessary to separate tokens.


\section{Scoping}
\label{sec:scoping}

Variable names must be unique within the scope of the entire \vnnlib{} specification.

TODO Ann

\section{Typing}
\label{sec:typing}

TODO Ann

\section{Semantics}
\label{sec:semantics}

TODO Ann

