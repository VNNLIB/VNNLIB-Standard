\documentclass[12pt,a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{todonotes}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{authblk}
\usepackage{algorithm, algpseudocode}
\usepackage{geometry}
\usepackage{booktabs} 
\usepackage{longtable} 
\usepackage{array}
\usepackage{geometry}
\usepackage{tikz}
\usepackage{caption} 

\renewcommand{\lstlistingname}{Example}
\newcommand{\ie}{\textit{i.e.}}

%customized todo
\definecolor{lightgreen}{rgb}{0.8,1.0,0.8}
\definecolor{red}{rgb}{0.8,0,0}
\definecolor{green}{rgb}{0,0.8,0}
\definecolor{blue}{rgb}{0,0,1}
% Define some colors for listings
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{keywordblue}{rgb}{0.13,0.13,1}
\definecolor{stringred}{rgb}{0.8,0,0}

% Listings style for BNFC commands
\lstdefinestyle{lbnf}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{keywordblue}\bfseries,
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{stringred},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=1,
    frame=lines,
    xleftmargin=2em,
    framexleftmargin=1.5em,
    escapeinside={\%*}{*} 
}

% Listings style for Bash/CLI commands
\lstdefinestyle{bash}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{keywordblue}\bfseries,
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{stringred},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    frame=lines,
    xleftmargin=2em,
    framexleftmargin=1.5em,
    escapeinside={\%*}{*} 
}

\newcommand{\mytodo}[1]{\todo[inline,color=lightgreen]{TODO:#1}}
\newcommand{\mnote}[2][]{\todo[inline,color=blue!10,#1]{Matthew: #2}}
\newcommand{\myremark}[1]{\todo[inline, color=lightgreen]{\textbf{Remark:} #1}}

\title{
	The VNN-LIB Standard \\ 
	Version 2.0 (draft)
}

\author[1]{Stefano Demarchi}
\author[2]{Dario Guidotti}
\author[2]{Luca Pulina}
\author[1]{Armando Tacchella}

\author[3]{Ann Roy}
\author[3]{Allen Antony}
\author[3]{Matthew Daggitt}

\affil[1]{University of Genoa, Viale Causa 13, 16145 Genoa, Italy}
\affil[2]{University of Sassari, Via Roma 151, 07100 Sassari, Italy}
\affil[3]{University of Western Australia, 35 Stirling Hwy, Crawley WA 6009, Australia}
  
\begin{document}

\maketitle

\begin{abstract}
This document presents VNN-LIB, a standard that formalises the query language for neural network verifiers. The standard uses the 
Open Neural Network Exchange (ONNX) format for model description and builds upon the Satisfiability Modulo Theories Library (SMT-LIB) 
format for query specification. Key among the standard is a formally defined syntax and semantics, complimentary tooling, as well as a 
command-line interface for verifiers. The goal is to foster greater robustness and interoperability in the neural network verification 
landscape.
\end{abstract}

\input{chapters/introduction.tex}
\input{chapters/models.tex}
\input{chapters/query_language.tex}
\input{chapters/logics.tex}
\input{chapters/verifier_interface.tex}

\appendix
\chapter{VNN-LIB LBNF Grammar}\label{app:lbnf_grammar}

\begin{thebibliography}{9} 

\bibitem{1} 
D. Tang, B. Qin, and T. Liu, ``Document modelling with gated recurrent neural network for sentiment classification,'' in \emph{Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing}, 2015, pp. 1422--1432.

\bibitem{2} 
M. Bojarski, et al., ``End to end learning for self-driving cars,'' \emph{arXiv preprint arXiv:1604.07316}, 2016.

\bibitem{3} 
C. Szegedy, et al., ``Intriguing properties of neural networks,'' \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem{4} 
P. Zhang et al., ``White-box fairness testing through adversarial sampling,'' in \emph{2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)}, New York, NY, USA:\@ ACM, 2020, pp. 949--960.\'doi: \href{https://doi.org/10.1145/3377811.3380331}{10.1145/3377811.3380331}.

\bibitem{5} 
S. Demarchi, D. Guidotti, L. Pulina, and A. Tacchella, ``Supporting Standardization of Neural Networks Verification with VNN-LIB and CoCoNet,'' in \emph{Proc. 6th Int. Workshop on Formal Methods for ML-Enabled Autonomous Systems (FoMLAS 2023)}, 2023, pp. 47--58.

\bibitem{6} 
C. Brix, S. Bak, C. Liu, and T. T. Johnson, ``The Fourth International Verification of Neural Networks Competition (VNN-COMP 2023): Summary and Results,'' 2023, doi: \href{https://doi.org/10.48550/arxiv.2312.16760}{10.48550/arxiv.2312.16760}.

\bibitem{7} 
L. C. Cordeiro et al., ``Neural Network Verification is a Programming Language Challenge,'' 2025, doi: \href{https://doi.org/10.48550/arxiv.2501.05867}{10.48550/arxiv.2501.05867}.

\bibitem{8} 
M. Forsberg and A. Ranta, ``The Labelled BNF Grammar Formalism,'' Department of Computing Science, Chalmers University of Technology and the University of Gothenburg, Gothenburg, Sweden, Feb. 11, 2005. [Online]. Available: \url{https://bnfc.digitalgrammars.com/LBNF-report.pdf}

\end{thebibliography}

\end{document}
